{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a02f25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import numpy\n",
    "from sklearn import linear_model\n",
    "\n",
    "# This will suppress any warnings, comment out if you'd like to preserve them\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Check formatting of submissions\n",
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N\n",
    "    \n",
    "# Read data\n",
    "answers = {}\n",
    "f = open(\"spoilers.json.gz\", 'r')\n",
    "dataset = []\n",
    "for l in f:\n",
    "    d = eval(l)\n",
    "    dataset.append(d)\n",
    "f.close()\n",
    "\n",
    "# A few utility data structures\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "\n",
    "for d in dataset:\n",
    "    u,i = d['user_id'],d['book_id']\n",
    "    reviewsPerUser[u].append(d)\n",
    "    reviewsPerItem[i].append(d)\n",
    "\n",
    "# Sort reviews per user by timestamp\n",
    "for u in reviewsPerUser:\n",
    "    reviewsPerUser[u].sort(key=lambda x: x['timestamp'])\n",
    "    \n",
    "# Same for reviews per item\n",
    "for i in reviewsPerItem:\n",
    "    reviewsPerItem[i].sort(key=lambda x: x['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d071b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE1a:1.970416294395752\n",
      "MSE1b:2.051966103395068\n"
     ]
    }
   ],
   "source": [
    "### 1a ##############################################################################\n",
    "# MSE function\n",
    "def MSE(y, ypred):\n",
    "    return sum([(a-b)**2 for (a,b) in zip(y,ypred)]) / len(y)\n",
    "y=[]\n",
    "ypred=[]\n",
    "for u in reviewsPerUser:\n",
    "    if len(reviewsPerUser[u])<=1:#skip those only have one review\n",
    "        continue\n",
    "    TobePred=reviewsPerUser[u][-1]\n",
    "    PreviousPred=reviewsPerUser[u][:-1]\n",
    "    y.append(TobePred['rating'])\n",
    "    sumRating=0\n",
    "    for pp in PreviousPred:\n",
    "        sumRating+=pp['rating']\n",
    "    avgRating=sumRating/len(PreviousPred)\n",
    "    ypred.append(avgRating)\n",
    "MSE1a=MSE(y,ypred)\n",
    "answers['Q1a'] = MSE1a\n",
    "assertFloat(answers['Q1a'])   \n",
    "print(\"MSE1a:{}\".format(MSE1a))\n",
    "\n",
    "### 1b ##############################################################################\n",
    "y=[]\n",
    "ypred=[]\n",
    "for i in reviewsPerItem:\n",
    "    if len(reviewsPerItem[i])<=1:#skip those only have one review\n",
    "        continue\n",
    "    TobePred=reviewsPerItem[i][-1]\n",
    "    PreviousPred=reviewsPerItem[i][:-1]\n",
    "    y.append(TobePred['rating'])\n",
    "    sumRating=0\n",
    "    for pp in PreviousPred:\n",
    "        sumRating+=pp['rating']\n",
    "    avgRating=sumRating/len(PreviousPred)\n",
    "    ypred.append(avgRating)\n",
    "\n",
    "MSE1b=MSE(y,ypred)\n",
    "answers['Q1b'] = MSE1b\n",
    "assertFloat(answers['Q1b'])\n",
    "print(\"MSE1b:{}\".format(MSE1b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36923e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers['Q2']:[2.666035950804163, 2.1542691579943236, 2.0280931357090237]\n"
     ]
    }
   ],
   "source": [
    "### 2 ###############################################################################\n",
    "answers['Q2'] = []\n",
    "for N in [1,2,3]:\n",
    "    #initialize\n",
    "    y=[]\n",
    "    ypred=[]\n",
    "    for u in reviewsPerUser:\n",
    "        if len(reviewsPerUser[u])<=1: #skip those who have less than N+1 reviews\n",
    "            continue\n",
    "        if len(reviewsPerUser[u])< N+1:\n",
    "            TobePred=reviewsPerUser[u][-1]\n",
    "            PreviousPred=reviewsPerUser[u][:-1]\n",
    "            y.append(TobePred['rating'])\n",
    "            sumRating=0\n",
    "            for pp in PreviousPred:\n",
    "                sumRating+=pp['rating']\n",
    "            avgRating=sumRating/len(PreviousPred)\n",
    "            ypred.append(avgRating)\n",
    "            \n",
    "        else:\n",
    "            TobePred=reviewsPerUser[u][-1]\n",
    "            PreviousPred=reviewsPerUser[u][-(N+1):-1]\n",
    "            y.append(TobePred['rating'])\n",
    "\n",
    "            sumRating=0\n",
    "            for pp in PreviousPred:\n",
    "                sumRating+=pp['rating']\n",
    "            avgRating=sumRating/len(PreviousPred)\n",
    "            ypred.append(avgRating)\n",
    "    mse=MSE(y,ypred)\n",
    "    answers['Q2'].append(mse)\n",
    "assertFloatList(answers['Q2'], 3)\n",
    "print(\"answers['Q2']:{}\".format(answers['Q2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "efffe88d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, 4], [1, 4, 4, 4]]\n",
      "[1.572336370720419, 1.5611067461571124, 1.5237646097739816]\n"
     ]
    }
   ],
   "source": [
    "### 3 ###############################################################################\n",
    "### 3a ##############################################################################\n",
    "\n",
    "def feature3(N, u): # For a user u and a window size of N\n",
    "    ratings=reviewsPerUser[u]\n",
    "    if len(ratings)<=N+1:\n",
    "        return None\n",
    "    temp=[]\n",
    "    for r in ratings[-N-1:-1]:\n",
    "        temp.append(r['rating'])\n",
    "    ans=[1]\n",
    "    ans.extend(temp[::-1])\n",
    "    return ans\n",
    "answers['Q3a'] = [feature3(2,dataset[0]['user_id']), feature3(3,dataset[0]['user_id'])]\n",
    "assert len(answers['Q3a']) == 2\n",
    "assert len(answers['Q3a'][0]) == 3\n",
    "assert len(answers['Q3a'][1]) == 4\n",
    "print(answers['Q3a'])\n",
    "\n",
    "### 3b ##############################################################################\n",
    "answers['Q3b'] = []\n",
    "for N in [1,2,3]:\n",
    "    Xtrain = []\n",
    "    ytrain = []\n",
    "    for u in reviewsPerUser:\n",
    "        if len(reviewsPerUser[u])<=N+1:\n",
    "            continue\n",
    "        feature=feature3(N, u)\n",
    "        TobePred=reviewsPerUser[u][-1]\n",
    "        ytrain.append(TobePred['rating'])\n",
    "        Xtrain.append(feature)\n",
    "    mod3 = linear_model.ARDRegression(fit_intercept=False)\n",
    "    mod3.fit(Xtrain,ytrain)\n",
    "    ypred = mod3.predict(Xtrain)\n",
    "    mse=MSE(ytrain,ypred)      \n",
    "    answers['Q3b'].append(mse)\n",
    "assertFloatList(answers['Q3b'], 3)\n",
    "print(answers['Q3b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "92271e63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers['Q4a']:[[1, 4, 4, 4, 4, 5, 4.2, 4.2, 4.2, 4.2, 4.2], [1, 0, 4, 0, 4, 0, 4, 0, 4, 0, 5, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]]\n",
      "answers['Q4b']:[1.5484453936907083, 1.5365288321572688]\n"
     ]
    }
   ],
   "source": [
    "### 4 ###############################################################################\n",
    "globalAverage = [d['rating'] for d in dataset]\n",
    "globalAverage = sum(globalAverage) / len(globalAverage)\n",
    "### 4a ##############################################################################\n",
    "def featureMeanValue(N, u): # For a user u and a window size of N\n",
    "    ratings=reviewsPerUser[u]\n",
    "    missingNum=(N+1)-len(ratings)\n",
    "    ans=[1]\n",
    "    if missingNum==N:\n",
    "        ans.extend([globalAverage]*missingNum)\n",
    "        return ans\n",
    "    elif missingNum<=0:\n",
    "        temp=[]\n",
    "        for r in ratings[-(N+1):-1]:\n",
    "            temp.append(r['rating'])\n",
    "        ans.extend(temp[::-1])\n",
    "        return ans\n",
    "    else:\n",
    "        temp=[]\n",
    "        for r in ratings[:-1]:\n",
    "            temp.append(r['rating'])\n",
    "        localAvg=sum(temp)/len(temp)\n",
    "        ans.extend(temp[::-1])\n",
    "        ans.extend([localAvg]*missingNum)\n",
    "        return ans    \n",
    "    \n",
    "def featureMissingValue(N, u):\n",
    "    ratings=reviewsPerUser[u]\n",
    "    missingNum=(N+1)-len(ratings)\n",
    "    ans=[1]\n",
    "    if missingNum==N:\n",
    "        for i in range(missingNum):\n",
    "            ans.extend([1,0])\n",
    "        return ans\n",
    "    elif missingNum<=0:\n",
    "        temp=ratings[-(N+1):-1]\n",
    "        temp=temp[::-1]\n",
    "        for t in temp:\n",
    "            ans.extend([0,t['rating']])\n",
    "        return ans\n",
    "    else:\n",
    "        temp=ratings[:-1]\n",
    "        temp=temp[::-1]\n",
    "        for t in temp:\n",
    "            ans.extend([0,t['rating']])\n",
    "        for i in range(missingNum):\n",
    "            ans.extend([1,0])\n",
    "        return ans\n",
    "    \n",
    "answers['Q4a'] = [featureMeanValue(10, dataset[0]['user_id']), featureMissingValue(10, dataset[0]['user_id'])]\n",
    "assert len(answers['Q4a']) == 2\n",
    "assert len(answers['Q4a'][0]) == 11\n",
    "assert len(answers['Q4a'][1]) == 21\n",
    "print(\"answers['Q4a']:{}\".format(answers['Q4a'] ))\n",
    "### 4b ##############################################################################\n",
    "answers['Q4b'] = []\n",
    "N=10\n",
    "for featFunc in [featureMeanValue, featureMissingValue]:\n",
    "    Xtrain = []\n",
    "    ytrain = []\n",
    "    for u in reviewsPerUser:\n",
    "        if len(reviewsPerUser[u])<=0:\n",
    "            continue\n",
    "        feature=featFunc(N, u)\n",
    "        TobePred=reviewsPerUser[u][-1]\n",
    "        ytrain.append(TobePred['rating'])\n",
    "        Xtrain.append(feature)\n",
    "    mod4 = linear_model.ARDRegression(fit_intercept=False)\n",
    "    mod4.fit(Xtrain,ytrain)\n",
    "    ypred = mod4.predict(Xtrain)\n",
    "    mse=MSE(ytrain,ypred)      \n",
    "    answers['Q4b'].append(mse)\n",
    "assertFloatList(answers[\"Q4b\"], 2)\n",
    "print(\"answers['Q4b']:{}\".format(answers['Q4b'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d1b0342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers['Q5a']:[1, 121, 0, 4]\n",
      "answers['Q5b']:[2384, 168945, 86232, 3615, 0.470265288006232]\n"
     ]
    }
   ],
   "source": [
    "### 5 ###############################################################################\n",
    "def feature5(sentence):\n",
    "    ans=[1]\n",
    "    lenChar=len(sentence)\n",
    "    countExclamation=0\n",
    "    numCapital=0\n",
    "    for c in sentence:\n",
    "        if c=='!':\n",
    "            countExclamation+=1\n",
    "        if c.isupper():\n",
    "            numCapital+=1\n",
    "    ans.extend([lenChar,countExclamation,numCapital])\n",
    "    return ans\n",
    "y = []\n",
    "X = []\n",
    "for d in dataset:\n",
    "    for spoiler,sentence in d['review_sentences']:\n",
    "        X.append(feature5(sentence))\n",
    "        y.append(spoiler)\n",
    "mod5 = linear_model.LogisticRegression(class_weight='balanced',C=1)\n",
    "mod5.fit(X,y)\n",
    "y_predict=mod5.predict(X)\n",
    "def accuracy_calculation(y,y_predict):\n",
    "    TruePt,TrueNg,FalsePt,FalseNg=0,0,0,0\n",
    "    for i in range(len(y_predict)):\n",
    "        if y_predict[i]==0:\n",
    "            if y[i]==0:\n",
    "                TrueNg+=1\n",
    "            else:\n",
    "                FalseNg+=1\n",
    "        else:\n",
    "            if y[i]==1:\n",
    "                TruePt+=1\n",
    "            else:\n",
    "                FalsePt+=1\n",
    "    BER=0.5*((FalsePt/(FalsePt+TrueNg))+(FalseNg/(FalseNg+TruePt)))\n",
    "    return [TruePt,TrueNg,FalsePt,FalseNg,BER]\n",
    "answers['Q5a'] = X[0]\n",
    "answers['Q5b'] = accuracy_calculation(y,y_predict)\n",
    "assert len(answers['Q5a']) == 4\n",
    "assertFloatList(answers['Q5b'], 5)\n",
    "print(\"answers['Q5a']:{}\".format(answers['Q5a'] ))\n",
    "print(\"answers['Q5b']:{}\".format(answers['Q5b'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b4cb66de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers['Q6a']:[1, 75, 0, 1, 0, 0, 0, 0, 0]\n",
      "answers['Q6b']:0.17042177629134153\n"
     ]
    }
   ],
   "source": [
    "### 6 ###############################################################################\n",
    "def feature6(review):\n",
    "    sentences = review['review_sentences']\n",
    "    sentence=sentences[5][1]\n",
    "    ans=[1]\n",
    "    lenChar=len(sentence)\n",
    "    countExclamation=0\n",
    "    numCapital=0\n",
    "    for c in sentence:\n",
    "        if c=='!':\n",
    "            countExclamation+=1\n",
    "        if c.isupper():\n",
    "            numCapital+=1\n",
    "    ans.extend([lenChar,countExclamation,numCapital])\n",
    "\n",
    "    for i in range(5):\n",
    "        ans.append(sentences[i][0])\n",
    "    return ans\n",
    "    \n",
    "y = []\n",
    "X = []\n",
    "\n",
    "for d in dataset:\n",
    "    sentences = d['review_sentences']\n",
    "    if len(sentences) < 6: continue\n",
    "    X.append(feature6(d))\n",
    "    y.append(sentences[5][0])\n",
    "\n",
    "mod6 = linear_model.LogisticRegression(class_weight='balanced',C=1)\n",
    "mod6.fit(X,y)\n",
    "y_predict=mod6.predict(X)\n",
    "answers['Q6a'] = X[0]\n",
    "answers['Q6b'] = accuracy_calculation(y,y_predict)[-1]\n",
    "assert len(answers['Q6a']) == 9\n",
    "assertFloat(answers['Q6b'])\n",
    "print(\"answers['Q6a']:{}\".format(answers['Q6a'] ))\n",
    "print(\"answers['Q6b']:{}\".format(answers['Q6b'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "49abe2db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bers:[0.13345081097468545, 0.1331097468546309, 0.14319766560557828, 0.14268606942549644, 0.14268606942549644]\n",
      "[0.13345081097468545, 0.1331097468546309, 0.14319766560557828, 0.14268606942549644, 0.14268606942549644, 0.1, 0.21333748810528996]\n"
     ]
    }
   ],
   "source": [
    "### 7 ###############################################################################\n",
    "y = []\n",
    "X = []\n",
    "\n",
    "for d in dataset:\n",
    "    sentences = d['review_sentences']\n",
    "    if len(sentences) < 6: continue\n",
    "    X.append(feature6(d))\n",
    "    y.append(sentences[5][0])\n",
    "# 50/25/25% train/valid/test split\n",
    "Xtrain, Xvalid, Xtest = X[:len(X)//2], X[len(X)//2:(3*len(X))//4], X[(3*len(X))//4:]\n",
    "ytrain, yvalid, ytest = y[:len(X)//2], y[len(X)//2:(3*len(X))//4], y[(3*len(X))//4:]\n",
    "bers=[]\n",
    "for c in [0.01, 0.1, 1, 10, 100]: \n",
    "    mod7 = linear_model.LogisticRegression(class_weight='balanced',C=c)\n",
    "    mod7.fit(Xtrain,ytrain)\n",
    "    yvalid_predict=mod7.predict(Xvalid)\n",
    "    bers.append(accuracy_calculation(yvalid,yvalid_predict)[-1])\n",
    "print(\"bers:{}\".format(bers))\n",
    "bestC=0.1\n",
    "mod7 = linear_model.LogisticRegression(class_weight='balanced',C=bestC)\n",
    "mod7.fit(Xtrain,ytrain)\n",
    "ytest_predict=mod7.predict(Xtest)\n",
    "ber=accuracy_calculation(ytest,ytest_predict)[-1]\n",
    "answers['Q7'] = bers + [bestC] + [ber]\n",
    "assertFloatList(answers['Q7'], 7)\n",
    "print(answers['Q7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e5253887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers['Q8']:1.8164934412791371\n"
     ]
    }
   ],
   "source": [
    "### 8 ###############################################################################\n",
    "#Jaccard Similarity\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom\n",
    "\n",
    "# 75/25% train/test split\n",
    "dataTrain = dataset[:15000]\n",
    "dataTest = dataset[15000:]\n",
    "\n",
    "# A few utilities\n",
    "\n",
    "itemAverages = defaultdict(list)\n",
    "ratingMean = []\n",
    "\n",
    "for d in dataTrain:\n",
    "    itemAverages[d['book_id']].append(d['rating'])\n",
    "    ratingMean.append(d['rating'])\n",
    "\n",
    "for i in itemAverages:\n",
    "    itemAverages[i] = sum(itemAverages[i]) / len(itemAverages[i])\n",
    "\n",
    "ratingMean = sum(ratingMean) / len(ratingMean)\n",
    "\n",
    "reviewsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(set)\n",
    "\n",
    "for d in dataTrain:\n",
    "    u,i = d['user_id'], d['book_id']\n",
    "    reviewsPerUser[u].append(d)\n",
    "    usersPerItem[i].add(u)\n",
    "\n",
    "# From my HW2 solution, welcome to reuse\n",
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        if item in itemAverages:\n",
    "            return itemAverages[item]\n",
    "        else:\n",
    "            return ratingMean\n",
    "predictions=[]\n",
    "labels=[]\n",
    "for d in dataTest:\n",
    "    user,item=d['user_id'],d['book_id']\n",
    "    predict=predictRating(user,item)\n",
    "    predictions.append(predict)\n",
    "    labels.append(d['rating'])\n",
    "answers[\"Q8\"] = MSE(predictions, labels)\n",
    "assertFloat(answers[\"Q8\"])\n",
    "print(\"answers['Q8']:{}\".format(answers[\"Q8\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "550bd0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4507"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(usersPerItem.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "23eb94f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset1:360\n",
      "dataset2:2860\n",
      "dataset3:1780\n",
      "dataTest=5000=dataset1+dataset2+dataset3=5000\n",
      "answers['Q9']:[1.742012484444442, 2.052681872005889, 1.452063234864505]\n"
     ]
    }
   ],
   "source": [
    "### 9 ###############################################################################\n",
    "dataTest1=[]\n",
    "dataTest2=[]\n",
    "dataTest3=[]\n",
    "for d in dataTest:\n",
    "    user,item=d['user_id'],d['book_id']\n",
    "    if item not in itemAverages:\n",
    "        dataTest1.append(d)\n",
    "    else:\n",
    "        if len(usersPerItem[item])>5:\n",
    "            dataTest3.append(d)\n",
    "        else:\n",
    "            dataTest2.append(d)\n",
    "        \n",
    "print(\"dataset1:{}\".format(len(dataTest1)))\n",
    "print(\"dataset2:{}\".format(len(dataTest2)))\n",
    "print(\"dataset3:{}\".format(len(dataTest3)))\n",
    "print(\"dataTest={}=dataset1+dataset2+dataset3={}\".format(len(dataTest),\\\n",
    "                    sum([len(dataTest1),len(dataTest2),len(dataTest3)])))\n",
    "mseLst=[]\n",
    "for dataSet in [dataTest1,dataTest2,dataTest3]:\n",
    "    predictions=[]\n",
    "    labels=[]\n",
    "    for d in dataSet:\n",
    "        user,item=d['user_id'],d['book_id']\n",
    "        predict=predictRating(user,item)\n",
    "        predictions.append(predict)\n",
    "        labels.append(d['rating'])\n",
    "    mseLst.append(MSE(predictions, labels))\n",
    "answers[\"Q9\"] = mseLst\n",
    "assertFloatList(answers[\"Q9\"], 3)\n",
    "print(\"answers['Q9']:{}\".format(answers[\"Q9\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ff74c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10 ##############################################################################\n",
    "userAverages = defaultdict(list)\n",
    "for d in dataTrain:\n",
    "    userAverages[d['user_id']].append(d['rating'])\n",
    "for i in userAverages:\n",
    "    userAverages[i] = sum(userAverages[i]) / len(userAverages[i])\n",
    "\n",
    "def predictRating10(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        if item in itemAverages:\n",
    "            return itemAverages[item]\n",
    "        else:\n",
    "            if user in userAverages:\n",
    "                return userAverages[user]\n",
    "            return ratingMean\n",
    "predictions=[]\n",
    "labels=[]\n",
    "for d in dataTest1:\n",
    "    user,item=d['user_id'],d['book_id']\n",
    "    predict=predictRating10(user,item)\n",
    "    predictions.append(predict)\n",
    "    labels.append(d['rating'])\n",
    "itsMSE=MSE(predictions, labels)\n",
    "description=\"Build another dictionary called 'userAverages' which is similar to\\\n",
    "            'itemAverages' and records the averages of ratings per user, \\\n",
    "            who have appeared in trainDataSet. When finding the items has not \\\n",
    "            appeared in trainData, we turn to 'userAverages'. If the user has \\\n",
    "            appeared in trainData, then we use the average of this user's ratings \\\n",
    "            to predict the rating. If neither user nor the item has appeared in \\\n",
    "            the trainData, we can only return the global average of ratings.\"\n",
    "answers[\"Q10\"] = (description, itsMSE)\n",
    "assert type(answers[\"Q10\"][0]) == str\n",
    "assertFloat(answers[\"Q10\"][1])\n",
    "f = open(\"answers_midterm.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b755b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
